## Text Classification ##
* Summary:
    * Input: some text x (e.g. sentence, document)
    * Output: a label y (from some finite label set)
    * Goal: learn a mapping function f from x to y
* Sentiment Analysis ï¼ˆä½œä¸šå°±æ˜¯ï¼‰
    * Actual Task: Is the entire text of a review positive or negative?
    * 2 key components:
        * formal learning method
        * representation of the (input) data
* **Bag of Words**: Represent texts as their word counts
* **Naive Bayes**: 
    * Input Representation: Bag of words
    * Pr (ð‘™ð‘Žð‘ð‘’ð‘™|ð‘¡ð‘’ð‘¥ð‘¡)
    * å®žçŽ°çš„æ—¶å€™ï¼Œlong documentç”¨logä¼šè§£å†³på¤ªå°çš„é—®é¢˜
    * unknwonçš„æƒ…å†µï¼Œç”¨smoothing Pr(ð‘¤ð‘–|ð‘™ð‘Žð‘ð‘’ð‘™) â‰ˆ (ð‘“(ð‘¤ð‘–,ð‘™ð‘Žð‘ð‘’ð‘™) + ð›¼)/(ð‘“(ð‘¤, ð‘™ð‘Žð‘ð‘’ð‘™) + ð›¼ âˆ™ V)
* Evaluate Model:
    * True Table:
      | True Positive | False Positive |
      | ----------------| ------------- |
      | False Negative | True Negative |
    * Accuracy = (TP+TN)/(ALL)
    * Precision = (TP)/(TP+FP)
    * Recall = (TP)/(TP+FN)
* Improving Model:
    * Binarization: Presence of a word >>>> How many times a word occurs
    * (Log) Likelyhood Ratio